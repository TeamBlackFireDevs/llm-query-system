# ğŸš€ LLM-Powered Intelligent Query-Retrieval System

A production-ready document processing and intelligent query system designed for insurance, legal, HR, and compliance domains.

## âœ¨ Features

- **Multi-format Document Processing**: PDF, DOCX, TXT, Email files
- **Semantic Search**: Vector-based similarity search using OpenAI embeddings
- **Intelligent Chunking**: Smart text segmentation with overlap
- **RESTful API**: Complete FastAPI-based backend
- **Vector Storage**: FAISS (local) or Pinecone (cloud) support
- **Database Integration**: SQLAlchemy with PostgreSQL/SQLite
- **Docker Support**: Containerized deployment
- **Production Ready**: Logging, error handling, monitoring

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   FastAPI App   â”‚    â”‚  Document Proc  â”‚    â”‚  Vector Store   â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚  - REST API     â”‚â—„â”€â”€â–ºâ”‚  - Text Extract â”‚â—„â”€â”€â–ºâ”‚  - FAISS Index  â”‚
â”‚  - Auth         â”‚    â”‚  - Chunking     â”‚    â”‚  - Embeddings   â”‚
â”‚  - Validation   â”‚    â”‚  - Metadata     â”‚    â”‚  - Search       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â–¼                       â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   PostgreSQL    â”‚    â”‚   Query Engine  â”‚    â”‚   OpenAI API    â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚  - Documents    â”‚    â”‚  - Query Proc   â”‚    â”‚  - Embeddings   â”‚
â”‚  - Chunks       â”‚    â”‚  - Results      â”‚    â”‚  - GPT-3.5      â”‚
â”‚  - Logs         â”‚    â”‚  - Explanations â”‚    â”‚  - Summaries    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Prerequisites

- Python 3.11+
- OpenAI API Key
- PostgreSQL (optional, SQLite by default)

### Installation

1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd llm-query-system
   ```

2. **Set up environment**
   ```bash
   cp .env.example .env
   # Edit .env with your API keys
   ```

3. **Run with startup script**
   ```bash
   chmod +x startup.sh
   ./startup.sh
   ```

### Docker Deployment

```bash
# Start with Docker Compose
docker-compose up -d

# Access the API
curl http://localhost:8000/health
```

## ğŸ“š API Documentation

### Document Upload
```bash
curl -X POST "http://localhost:8000/api/v1/upload" \
  -H "Content-Type: multipart/form-data" \
  -F "file=@document.pdf"
```

### Query Documents
```bash
curl -X POST "http://localhost:8000/api/v1/query" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "What are the insurance coverage details?",
    "max_results": 5,
    "similarity_threshold": 0.7
  }'
```

### List Documents
```bash
curl "http://localhost:8000/api/v1/documents"
```

## ğŸ”§ Configuration

### Environment Variables

| Variable | Description | Default |
|----------|-------------|---------|
| `OPENAI_API_KEY` | OpenAI API key (required) | - |
| `DATABASE_URL` | Database connection string | `sqlite:///./query_system.db` |
| `MAX_FILE_SIZE` | Maximum file upload size | `52428800` (50MB) |
| `CHUNK_SIZE` | Text chunk size | `1000` |
| `VECTOR_DIMENSION` | Embedding dimension | `1536` |

### Vector Store Options

- **FAISS (Local)**: Default, no external dependencies
- **Pinecone (Cloud)**: Set `USE_PINECONE=true` in `.env`

## ğŸ“Š System Monitoring

### Health Check
```bash
curl http://localhost:8000/health
```

### System Statistics
```bash
curl http://localhost:8000/api/v1/stats
```

## ğŸ› ï¸ Development

### Project Structure
```
llm-query-system/
â”œâ”€â”€ api/                 # API endpoints
â”œâ”€â”€ models/              # Database and Pydantic models
â”œâ”€â”€ services/            # Business logic
â”œâ”€â”€ utils/               # Utility functions
â”œâ”€â”€ uploads/             # Document storage
â”œâ”€â”€ vector_index/        # FAISS index files
â””â”€â”€ main.py             # Application entry point
```

### Running Tests
```bash
pytest tests/
```

### Code Quality
```bash
# Format code
black .

# Lint code
flake8 .
```

## ğŸ”’ Security

- **API Key Management**: Environment variables for sensitive data
- **File Validation**: Type and size restrictions
- **Input Sanitization**: Safe filename handling
- **Error Handling**: No sensitive data in error messages

## ğŸ“ˆ Performance

- **Async Processing**: Non-blocking document processing
- **Vector Optimization**: Efficient similarity search
- **Database Indexing**: Optimized queries
- **Caching**: FAISS index persistence

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests
5. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ†˜ Support

- **Documentation**: Check the API docs at `/docs`
- **Issues**: Report bugs via GitHub issues
- **Discussions**: Use GitHub discussions for questions

---

**Built with â¤ï¸ using FastAPI, OpenAI, and FAISS** 